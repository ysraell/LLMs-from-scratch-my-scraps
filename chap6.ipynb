{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2daade69-bb67-4014-ae09-6d2f62a506cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:35:19.784230Z",
     "iopub.status.busy": "2025-03-23T14:35:19.783690Z",
     "iopub.status.idle": "2025-03-23T14:35:19.790773Z",
     "shell.execute_reply": "2025-03-23T14:35:19.789577Z",
     "shell.execute_reply.started": "2025-03-23T14:35:19.784185Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = '/work/tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e13bc-f58b-43a7-b0ba-db423409b1f3",
   "metadata": {},
   "source": [
    "# Stage 1, steps 1 and 2: \n",
    "`Run once`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896404e0-b8b4-4d7d-9d4c-831606f5f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = f\"{base_path}/sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(\n",
    "        url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download \"\n",
    "              \"and extraction.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    with urllib.request.urlopen(url) as response:    #1\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:    #2\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)               #3\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de628de4-9c2e-43c3-88ed-1cbeb8f69b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da50f93-63db-4ff2-a20e-44c7f2c89608",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b8b54-d333-46cb-9ab4-a69207fd6c4e",
   "metadata": {},
   "source": [
    "### Undersampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5197f8f-86da-49b1-9ef2-720217c330d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]     #1\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
    "        num_spam, random_state=123\n",
    "    )                                         #2\n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])                               #3\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf939b2-114d-4537-97f7-5cad14d0642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7be240-f4f2-4606-9aa1-564e81fadcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)               #1\n",
    "    train_end = int(len(df) * train_frac)          #2\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3caa8-d8d9-4344-9b8b-36ce3271d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed7b97-713f-4124-8d68-3f7e333eba95",
   "metadata": {},
   "source": [
    "# Stage 1, steps 3:\n",
    "`Run for training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01cdf359-1748-48f2-857e-2461dabb70e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:35:26.179461Z",
     "iopub.status.busy": "2025-03-23T14:35:26.178973Z",
     "iopub.status.idle": "2025-03-23T14:35:26.309953Z",
     "shell.execute_reply": "2025-03-23T14:35:26.309664Z",
     "shell.execute_reply.started": "2025-03-23T14:35:26.179419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53fbc0a-bf25-422f-81e8-5c5c53355089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:35:59.268475Z",
     "iopub.status.busy": "2025-03-23T14:35:59.267897Z",
     "iopub.status.idle": "2025-03-23T14:35:59.450003Z",
     "shell.execute_reply": "2025-03-23T14:35:59.449637Z",
     "shell.execute_reply.started": "2025-03-23T14:35:59.268427Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        max_length = min(max_length, 1024) if max_length is not None else None\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6438fe39-25ab-4183-a876-0d07b4a1107b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:35:59.902850Z",
     "iopub.status.busy": "2025-03-23T14:35:59.902138Z",
     "iopub.status.idle": "2025-03-23T14:35:59.933371Z",
     "shell.execute_reply": "2025-03-23T14:35:59.932981Z",
     "shell.execute_reply.started": "2025-03-23T14:35:59.902804Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=f\"{base_path}/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ad29b9-4f77-42c6-b7f8-e020b910936e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:00.810702Z",
     "iopub.status.busy": "2025-03-23T14:36:00.810149Z",
     "iopub.status.idle": "2025-03-23T14:36:00.818068Z",
     "shell.execute_reply": "2025-03-23T14:36:00.816686Z",
     "shell.execute_reply.started": "2025-03-23T14:36:00.810657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c05115-aa84-4faf-90e4-8d33815043f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:01.483672Z",
     "iopub.status.busy": "2025-03-23T14:36:01.483140Z",
     "iopub.status.idle": "2025-03-23T14:36:01.510831Z",
     "shell.execute_reply": "2025-03-23T14:36:01.509321Z",
     "shell.execute_reply.started": "2025-03-23T14:36:01.483631Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=f\"{base_path}/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=f\"{base_path}/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb497e4-b865-4a75-9a9e-1696f94413d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:02.148345Z",
     "iopub.status.busy": "2025-03-23T14:36:02.147830Z",
     "iopub.status.idle": "2025-03-23T14:36:02.158509Z",
     "shell.execute_reply": "2025-03-23T14:36:02.157175Z",
     "shell.execute_reply.started": "2025-03-23T14:36:02.148305Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0      #1\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "479c886c-ceb4-4de3-8ccd-b55224ed1108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:03.230115Z",
     "iopub.status.busy": "2025-03-23T14:36:03.229606Z",
     "iopub.status.idle": "2025-03-23T14:36:03.279063Z",
     "shell.execute_reply": "2025-03-23T14:36:03.278561Z",
     "shell.execute_reply.started": "2025-03-23T14:36:03.230075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118fae53-ac66-4e14-9dc3-78f16c69abfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:03.630909Z",
     "iopub.status.busy": "2025-03-23T14:36:03.630378Z",
     "iopub.status.idle": "2025-03-23T14:36:03.637012Z",
     "shell.execute_reply": "2025-03-23T14:36:03.635147Z",
     "shell.execute_reply.started": "2025-03-23T14:36:03.630870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0896e3ec-6738-458e-9dad-e9e600fdbab5",
   "metadata": {},
   "source": [
    "# Stage 2, steps 4 and 5:\n",
    "`Run for training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8015a4e4-6fc6-484f-8339-b8e60a69dc4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:04.863411Z",
     "iopub.status.busy": "2025-03-23T14:36:04.862853Z",
     "iopub.status.idle": "2025-03-23T14:36:04.871282Z",
     "shell.execute_reply": "2025-03-23T14:36:04.869192Z",
     "shell.execute_reply.started": "2025-03-23T14:36:04.863363Z"
    }
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,          #1\n",
    "    \"context_length\": 1024,       #2\n",
    "    \"drop_rate\": 0.0,             #3\n",
    "    \"qkv_bias\": True              #4\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0863260b-6504-4b02-8966-7eb9cfc7fff5",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:05.396039Z",
     "iopub.status.busy": "2025-03-23T14:36:05.395529Z",
     "iopub.status.idle": "2025-03-23T14:36:12.683204Z",
     "shell.execute_reply": "2025-03-23T14:36:12.682634Z",
     "shell.execute_reply.started": "2025-03-23T14:36:05.395997Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:36:05.555412: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-23 14:36:05.563327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742740565.572681     861 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742740565.575482     861 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742740565.582729     861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742740565.582737     861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742740565.582738     861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742740565.582739     861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-23 14:36:05.585502: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from chap4 import GPTModel\n",
    "from chap5 import load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=f\"{base_path}/gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f44674a-ab97-4320-a3d3-75b523af10af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:36:17.168265Z",
     "iopub.status.busy": "2025-03-23T14:36:17.167412Z",
     "iopub.status.idle": "2025-03-23T14:36:17.664361Z",
     "shell.execute_reply": "2025-03-23T14:36:17.663973Z",
     "shell.execute_reply.started": "2025-03-23T14:36:17.168222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from chap4 import generate_text_simple\n",
    "from chap5 import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d8d257-133c-43d1-b60d-539d40369c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:39:44.644183Z",
     "iopub.status.busy": "2025-03-23T14:39:44.643661Z",
     "iopub.status.idle": "2025-03-23T14:39:45.881341Z",
     "shell.execute_reply": "2025-03-23T14:39:45.880664Z",
     "shell.execute_reply.started": "2025-03-23T14:39:44.644144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8b64ade-3dbe-4fa6-9826-db4f06ca66e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:41:21.495444Z",
     "iopub.status.busy": "2025-03-23T14:41:21.494935Z",
     "iopub.status.idle": "2025-03-23T14:41:21.506697Z",
     "shell.execute_reply": "2025-03-23T14:41:21.505609Z",
     "shell.execute_reply.started": "2025-03-23T14:41:21.495406Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1018e1b-8e5e-4da0-94d5-d00ff8100487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:42:26.177019Z",
     "iopub.status.busy": "2025-03-23T14:42:26.176502Z",
     "iopub.status.idle": "2025-03-23T14:42:27.465394Z",
     "shell.execute_reply": "2025-03-23T14:42:27.465048Z",
     "shell.execute_reply.started": "2025-03-23T14:42:26.176977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer).to(device),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbaa1e-d6b5-4b1e-b4dc-b064f33f43ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:43:21.365051Z",
     "iopub.status.busy": "2025-03-23T14:43:21.364544Z",
     "iopub.status.idle": "2025-03-23T14:43:21.368322Z",
     "shell.execute_reply": "2025-03-23T14:43:21.367286Z",
     "shell.execute_reply.started": "2025-03-23T14:43:21.365009Z"
    }
   },
   "source": [
    "### Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd7830-a75a-4b50-bbda-05eeaf4b4d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
