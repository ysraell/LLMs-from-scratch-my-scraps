{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5efeac-ac87-4df3-8aab-480cc5036aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.542297Z",
     "iopub.status.busy": "2025-03-30T22:14:34.542141Z",
     "iopub.status.idle": "2025-03-30T22:14:34.553665Z",
     "shell.execute_reply": "2025-03-30T22:14:34.553177Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.542280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6278b3df-ad2b-4f7b-bf73-bd971127f871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.554464Z",
     "iopub.status.busy": "2025-03-30T22:14:34.554271Z",
     "iopub.status.idle": "2025-03-30T22:14:34.568747Z",
     "shell.execute_reply": "2025-03-30T22:14:34.567976Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.554444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af7278f-af46-4ee4-846e-9ef891f31bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.569994Z",
     "iopub.status.busy": "2025-03-30T22:14:34.569652Z",
     "iopub.status.idle": "2025-03-30T22:14:34.578155Z",
     "shell.execute_reply": "2025-03-30T22:14:34.577281Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.569960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a5f161-ec92-4e58-addb-688c9ce7dd40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.579830Z",
     "iopub.status.busy": "2025-03-30T22:14:34.579239Z",
     "iopub.status.idle": "2025-03-30T22:14:34.591683Z",
     "shell.execute_reply": "2025-03-30T22:14:34.590541Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.579773Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d04a54a-54cd-4d12-a590-4377ea0734b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.593304Z",
     "iopub.status.busy": "2025-03-30T22:14:34.592847Z",
     "iopub.status.idle": "2025-03-30T22:14:34.606701Z",
     "shell.execute_reply": "2025-03-30T22:14:34.605373Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.593239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08119765-1c9d-46d4-87ed-fda089eb7a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.613360Z",
     "iopub.status.busy": "2025-03-30T22:14:34.612730Z",
     "iopub.status.idle": "2025-03-30T22:14:34.619146Z",
     "shell.execute_reply": "2025-03-30T22:14:34.618182Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.613317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba4c211-80f6-4141-b48e-80a3b5b87880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.620800Z",
     "iopub.status.busy": "2025-03-30T22:14:34.620283Z",
     "iopub.status.idle": "2025-03-30T22:14:34.628836Z",
     "shell.execute_reply": "2025-03-30T22:14:34.628019Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.620762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)    #1\n",
    "test_portion = int(len(data) * 0.1)            #2\n",
    "val_portion = len(data) - train_portion - test_portion    #3\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35153c88-2eca-4acf-9b32-34befcdfd2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:34.630048Z",
     "iopub.status.busy": "2025-03-30T22:14:34.629742Z",
     "iopub.status.idle": "2025-03-30T22:14:35.379913Z",
     "shell.execute_reply": "2025-03-30T22:14:35.379422Z",
     "shell.execute_reply.started": "2025-03-30T22:14:34.630017Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:         #1\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bada5d-148d-4684-85ba-454ae48f8900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.380393Z",
     "iopub.status.busy": "2025-03-30T22:14:35.380278Z",
     "iopub.status.idle": "2025-03-30T22:14:35.518037Z",
     "shell.execute_reply": "2025-03-30T22:14:35.517685Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.380385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f45719-0fd5-4fda-a932-c42167188245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.518498Z",
     "iopub.status.busy": "2025-03-30T22:14:35.518399Z",
     "iopub.status.idle": "2025-03-30T22:14:35.520910Z",
     "shell.execute_reply": "2025-03-30T22:14:35.520686Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.518489Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)   #1\n",
    "    inputs_lst = []\n",
    "    for item in batch:     #2\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])    #3\n",
    "        inputs_lst.append(inputs)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)     #4\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a567f68f-645e-4462-9249-cd1468fe7d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.521289Z",
     "iopub.status.busy": "2025-03-30T22:14:35.521144Z",
     "iopub.status.idle": "2025-03-30T22:14:35.536020Z",
     "shell.execute_reply": "2025-03-30T22:14:35.535721Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.521281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4a69e7-5c49-4c31-a113-454259e42068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.536357Z",
     "iopub.status.busy": "2025-03-30T22:14:35.536277Z",
     "iopub.status.idle": "2025-03-30T22:14:35.548154Z",
     "shell.execute_reply": "2025-03-30T22:14:35.547610Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.536349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])     #1\n",
    "        targets = torch.tensor(padded[1:])    #2\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d69f38-e504-454e-8a76-304e1855be2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.548504Z",
     "iopub.status.busy": "2025-03-30T22:14:35.548401Z",
     "iopub.status.idle": "2025-03-30T22:14:35.559266Z",
     "shell.execute_reply": "2025-03-30T22:14:35.558559Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.548494Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (                               #1\n",
    "            new_item + [pad_token_id] *          #1\n",
    "            (batch_max_length - len(new_item))   #1\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])      #2\n",
    "        targets = torch.tensor(padded[1:])     #3\n",
    "        mask = targets == pad_token_id              #4\n",
    "        indices = torch.nonzero(mask).squeeze()     #4\n",
    "        if indices.numel() > 1:                     #4\n",
    "            targets[indices[1:]] = ignore_index     #4\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]       #5\n",
    "            targets = targets[:allowed_max_length]     #5\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf668db8-8730-456d-9379-19906b5110e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.559728Z",
     "iopub.status.busy": "2025-03-30T22:14:35.559592Z",
     "iopub.status.idle": "2025-03-30T22:14:35.571785Z",
     "shell.execute_reply": "2025-03-30T22:14:35.571151Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.559715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aef0e1e9-5184-4bee-81dd-e18fb71cb6db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.572582Z",
     "iopub.status.busy": "2025-03-30T22:14:35.572411Z",
     "iopub.status.idle": "2025-03-30T22:14:35.584954Z",
     "shell.execute_reply": "2025-03-30T22:14:35.584166Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.572566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],     #1\n",
    "     [-0.5, 1.5]]      #2\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cc6368-7b92-4140-8f4a-9b089ba39c8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.585448Z",
     "iopub.status.busy": "2025-03-30T22:14:35.585342Z",
     "iopub.status.idle": "2025-03-30T22:14:35.592337Z",
     "shell.execute_reply": "2025-03-30T22:14:35.592065Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.585436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]      #1\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7da1a6e-8959-4889-b00d-498593366592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.592836Z",
     "iopub.status.busy": "2025-03-30T22:14:35.592660Z",
     "iopub.status.idle": "2025-03-30T22:14:35.601043Z",
     "shell.execute_reply": "2025-03-30T22:14:35.600773Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.592825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97984da8-de74-4859-b692-60e7a283d58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.601529Z",
     "iopub.status.busy": "2025-03-30T22:14:35.601362Z",
     "iopub.status.idle": "2025-03-30T22:14:35.718720Z",
     "shell.execute_reply": "2025-03-30T22:14:35.718326Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.601519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():   #1\n",
    "#     device = torch.device(\"mps\")\"      \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4af0a92-e39d-4590-b00a-92594fd3e88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.719105Z",
     "iopub.status.busy": "2025-03-30T22:14:35.719001Z",
     "iopub.status.idle": "2025-03-30T22:14:35.732755Z",
     "shell.execute_reply": "2025-03-30T22:14:35.732513Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.719096Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06f25e1a-5a19-4125-bdc7-59ba3affef40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.733128Z",
     "iopub.status.busy": "2025-03-30T22:14:35.732990Z",
     "iopub.status.idle": "2025-03-30T22:14:35.761424Z",
     "shell.execute_reply": "2025-03-30T22:14:35.761025Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.733116Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0      #1\n",
    "batch_size = 2\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18a561f-f44d-442e-aa94-36c99cdec08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.762812Z",
     "iopub.status.busy": "2025-03-30T22:14:35.762694Z",
     "iopub.status.idle": "2025-03-30T22:14:35.970695Z",
     "shell.execute_reply": "2025-03-30T22:14:35.970293Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.762805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 47]) torch.Size([2, 47])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 49]) torch.Size([2, 49])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 48]) torch.Size([2, 48])\n",
      "torch.Size([2, 48]) torch.Size([2, 48])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 48]) torch.Size([2, 48])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 91]) torch.Size([2, 91])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 46]) torch.Size([2, 46])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 49]) torch.Size([2, 49])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 89]) torch.Size([2, 89])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 88]) torch.Size([2, 88])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 87]) torch.Size([2, 87])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 49]) torch.Size([2, 49])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 47]) torch.Size([2, 47])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 46]) torch.Size([2, 46])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 46]) torch.Size([2, 46])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 91]) torch.Size([2, 91])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 81]) torch.Size([2, 81])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 49]) torch.Size([2, 49])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 82]) torch.Size([2, 82])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 46]) torch.Size([2, 46])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 91]) torch.Size([2, 91])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 49]) torch.Size([2, 49])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 50]) torch.Size([2, 50])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 51]) torch.Size([2, 51])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c706f7d5-b4e3-4db7-8105-28e562084a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:35.971020Z",
     "iopub.status.busy": "2025-03-30T22:14:35.970938Z",
     "iopub.status.idle": "2025-03-30T22:14:35.974168Z",
     "shell.execute_reply": "2025-03-30T22:14:35.973966Z",
     "shell.execute_reply.started": "2025-03-30T22:14:35.971013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.device, targets.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b33affc-afd9-48db-867d-810a85f76c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:07:39.883471Z",
     "iopub.status.busy": "2025-03-30T23:07:39.882958Z",
     "iopub.status.idle": "2025-03-30T23:07:48.626029Z",
     "shell.execute_reply": "2025-03-30T23:07:48.625590Z",
     "shell.execute_reply.started": "2025-03-30T23:07:39.883429Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:07:40.111869: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-30 23:07:40.120246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743376060.129922    1103 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743376060.132811    1103 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743376060.140055    1103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743376060.140065    1103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743376060.140066    1103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743376060.140067    1103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 23:07:40.142755: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: /work/tmp/gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from chap4 import GPTModel, generate_text_simple\n",
    "from chap5 import load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, \n",
    "    models_dir=\"/work/tmp/gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf66201e-6b68-43e8-9c11-d98f60c1b450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:43.512822Z",
     "iopub.status.busy": "2025-03-30T22:14:43.512571Z",
     "iopub.status.idle": "2025-03-30T22:14:43.519534Z",
     "shell.execute_reply": "2025-03-30T22:14:43.519288Z",
     "shell.execute_reply.started": "2025-03-30T22:14:43.512812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3475eff7-d6b7-4771-bb0f-a8a4f8ac1a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:43.519908Z",
     "iopub.status.busy": "2025-03-30T22:14:43.519801Z",
     "iopub.status.idle": "2025-03-30T22:14:45.803563Z",
     "shell.execute_reply": "2025-03-30T22:14:45.803202Z",
     "shell.execute_reply.started": "2025-03-30T22:14:43.519901Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from chap5 import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c228d018-5148-4c8d-b869-1d1c0d65ea78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:45.804081Z",
     "iopub.status.busy": "2025-03-30T22:14:45.803942Z",
     "iopub.status.idle": "2025-03-30T22:14:45.825206Z",
     "shell.execute_reply": "2025-03-30T22:14:45.824915Z",
     "shell.execute_reply.started": "2025-03-30T22:14:45.804070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Instruction:\\n\\nConvert the active\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35451385-cc83-4b23-9aaf-f1d284ce5ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:45.825546Z",
     "iopub.status.busy": "2025-03-30T22:14:45.825467Z",
     "iopub.status.idle": "2025-03-30T22:14:45.845179Z",
     "shell.execute_reply": "2025-03-30T22:14:45.844943Z",
     "shell.execute_reply.started": "2025-03-30T22:14:45.825539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6430fa-8381-4fbd-8e6d-c45f975933fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:45.845496Z",
     "iopub.status.busy": "2025-03-30T22:14:45.845419Z",
     "iopub.status.idle": "2025-03-30T22:14:45.864316Z",
     "shell.execute_reply": "2025-03-30T22:14:45.864073Z",
     "shell.execute_reply.started": "2025-03-30T22:14:45.845489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from chap5 import calc_loss_loader, train_model_simple, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45be0f3c-30f0-4145-af2b-a15e19ff1b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:45.864632Z",
     "iopub.status.busy": "2025-03-30T22:14:45.864550Z",
     "iopub.status.idle": "2025-03-30T22:14:46.774696Z",
     "shell.execute_reply": "2025-03-30T22:14:46.774442Z",
     "shell.execute_reply.started": "2025-03-30T22:14:45.864624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.089017629623413\n",
      "Validation loss: 4.00831356048584\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fc14492-df75-4d9d-b25f-549e31e09f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:14:46.775112Z",
     "iopub.status.busy": "2025-03-30T22:14:46.775003Z",
     "iopub.status.idle": "2025-03-30T22:22:17.118831Z",
     "shell.execute_reply": "2025-03-30T22:22:17.118196Z",
     "shell.execute_reply.started": "2025-03-30T22:14:46.775103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.180, Val loss 3.139\n",
      "Ep 1 (Step 000005): Train loss 1.527, Val loss 1.800\n",
      "Ep 1 (Step 000010): Train loss 1.223, Val loss 1.315\n",
      "Ep 1 (Step 000015): Train loss 1.004, Val loss 1.215\n",
      "Ep 1 (Step 000020): Train loss 1.025, Val loss 1.187\n",
      "Ep 1 (Step 000025): Train loss 0.914, Val loss 1.147\n",
      "Ep 1 (Step 000030): Train loss 1.059, Val loss 1.144\n",
      "Ep 1 (Step 000035): Train loss 1.131, Val loss 1.129\n",
      "Ep 1 (Step 000040): Train loss 0.858, Val loss 1.091\n",
      "Ep 1 (Step 000045): Train loss 1.063, Val loss 1.072\n",
      "Ep 1 (Step 000050): Train loss 0.899, Val loss 1.062\n",
      "Ep 1 (Step 000055): Train loss 1.137, Val loss 1.063\n",
      "Ep 1 (Step 000060): Train loss 1.019, Val loss 1.047\n",
      "Ep 1 (Step 000065): Train loss 0.657, Val loss 1.023\n",
      "Ep 1 (Step 000070): Train loss 0.694, Val loss 1.028\n",
      "Ep 1 (Step 000075): Train loss 0.986, Val loss 1.018\n",
      "Ep 1 (Step 000080): Train loss 0.705, Val loss 1.012\n",
      "Ep 1 (Step 000085): Train loss 0.780, Val loss 1.010\n",
      "Ep 1 (Step 000090): Train loss 0.738, Val loss 1.017\n",
      "Ep 1 (Step 000095): Train loss 0.662, Val loss 0.999\n",
      "Ep 1 (Step 000100): Train loss 0.998, Val loss 0.989\n",
      "Ep 1 (Step 000105): Train loss 0.956, Val loss 0.995\n",
      "Ep 1 (Step 000110): Train loss 0.728, Val loss 0.989\n",
      "Ep 1 (Step 000115): Train loss 1.009, Val loss 0.987\n",
      "Ep 1 (Step 000120): Train loss 0.758, Val loss 0.990\n",
      "Ep 1 (Step 000125): Train loss 0.761, Val loss 0.984\n",
      "Ep 1 (Step 000130): Train loss 0.811, Val loss 0.972\n",
      "Ep 1 (Step 000135): Train loss 0.789, Val loss 0.963\n",
      "Ep 1 (Step 000140): Train loss 0.846, Val loss 0.955\n",
      "Ep 1 (Step 000145): Train loss 0.651, Val loss 0.951\n",
      "Ep 1 (Step 000150): Train loss 0.699, Val loss 0.962\n",
      "Ep 1 (Step 000155): Train loss 0.737, Val loss 0.970\n",
      "Ep 1 (Step 000160): Train loss 0.969, Val loss 0.964\n",
      "Ep 1 (Step 000165): Train loss 0.689, Val loss 0.962\n",
      "Ep 1 (Step 000170): Train loss 0.754, Val loss 0.965\n",
      "Ep 1 (Step 000175): Train loss 0.601, Val loss 0.956\n",
      "Ep 1 (Step 000180): Train loss 0.635, Val loss 0.943\n",
      "Ep 1 (Step 000185): Train loss 0.865, Val loss 0.931\n",
      "Ep 1 (Step 000190): Train loss 0.645, Val loss 0.923\n",
      "Ep 1 (Step 000195): Train loss 0.797, Val loss 0.921\n",
      "Ep 1 (Step 000200): Train loss 0.817, Val loss 0.927\n",
      "Ep 1 (Step 000205): Train loss 0.939, Val loss 0.934\n",
      "Ep 1 (Step 000210): Train loss 0.541, Val loss 0.932\n",
      "Ep 1 (Step 000215): Train loss 0.785, Val loss 0.926\n",
      "Ep 1 (Step 000220): Train loss 0.486, Val loss 0.931\n",
      "Ep 1 (Step 000225): Train loss 0.867, Val loss 0.932\n",
      "Ep 1 (Step 000230): Train loss 0.727, Val loss 0.916\n",
      "Ep 1 (Step 000235): Train loss 0.820, Val loss 0.908\n",
      "Ep 1 (Step 000240): Train loss 0.835, Val loss 0.900\n",
      "Ep 1 (Step 000245): Train loss 0.818, Val loss 0.894\n",
      "Ep 1 (Step 000250): Train loss 0.610, Val loss 0.885\n",
      "Ep 1 (Step 000255): Train loss 0.649, Val loss 0.887\n",
      "Ep 1 (Step 000260): Train loss 0.625, Val loss 0.889\n",
      "Ep 1 (Step 000265): Train loss 0.689, Val loss 0.896\n",
      "Ep 1 (Step 000270): Train loss 0.608, Val loss 0.895\n",
      "Ep 1 (Step 000275): Train loss 0.578, Val loss 0.896\n",
      "Ep 1 (Step 000280): Train loss 0.596, Val loss 0.900\n",
      "Ep 1 (Step 000285): Train loss 0.675, Val loss 0.884\n",
      "Ep 1 (Step 000290): Train loss 0.677, Val loss 0.874\n",
      "Ep 1 (Step 000295): Train loss 0.560, Val loss 0.869\n",
      "Ep 1 (Step 000300): Train loss 0.636, Val loss 0.874\n",
      "Ep 1 (Step 000305): Train loss 0.591, Val loss 0.864\n",
      "Ep 1 (Step 000310): Train loss 0.502, Val loss 0.861\n",
      "Ep 1 (Step 000315): Train loss 0.631, Val loss 0.855\n",
      "Ep 1 (Step 000320): Train loss 0.670, Val loss 0.854\n",
      "Ep 1 (Step 000325): Train loss 0.436, Val loss 0.859\n",
      "Ep 1 (Step 000330): Train loss 0.449, Val loss 0.850\n",
      "Ep 1 (Step 000335): Train loss 0.755, Val loss 0.849\n",
      "Ep 1 (Step 000340): Train loss 0.537, Val loss 0.851\n",
      "Ep 1 (Step 000345): Train loss 0.562, Val loss 0.854\n",
      "Ep 1 (Step 000350): Train loss 0.541, Val loss 0.853\n",
      "Ep 1 (Step 000355): Train loss 0.648, Val loss 0.849\n",
      "Ep 1 (Step 000360): Train loss 0.417, Val loss 0.856\n",
      "Ep 1 (Step 000365): Train loss 0.635, Val loss 0.860\n",
      "Ep 1 (Step 000370): Train loss 0.522, Val loss 0.858\n",
      "Ep 1 (Step 000375): Train loss 0.538, Val loss 0.853\n",
      "Ep 1 (Step 000380): Train loss 0.594, Val loss 0.852\n",
      "Ep 1 (Step 000385): Train loss 0.570, Val loss 0.858\n",
      "Ep 1 (Step 000390): Train loss 0.631, Val loss 0.858\n",
      "Ep 1 (Step 000395): Train loss 0.438, Val loss 0.843\n",
      "Ep 1 (Step 000400): Train loss 0.510, Val loss 0.838\n",
      "Ep 1 (Step 000405): Train loss 0.556, Val loss 0.849\n",
      "Ep 1 (Step 000410): Train loss 0.786, Val loss 0.862\n",
      "Ep 1 (Step 000415): Train loss 0.487, Val loss 0.859\n",
      "Ep 1 (Step 000420): Train loss 0.519, Val loss 0.864\n",
      "Ep 1 (Step 000425): Train loss 0.432, Val loss 0.861\n",
      "Ep 1 (Step 000430): Train loss 0.516, Val loss 0.852\n",
      "Ep 1 (Step 000435): Train loss 0.493, Val loss 0.845\n",
      "Ep 1 (Step 000440): Train loss 0.609, Val loss 0.845\n",
      "Ep 1 (Step 000445): Train loss 0.489, Val loss 0.843\n",
      "Ep 1 (Step 000450): Train loss 0.505, Val loss 0.846\n",
      "Ep 1 (Step 000455): Train loss 0.426, Val loss 0.849\n",
      "Ep 1 (Step 000460): Train loss 0.515, Val loss 0.864\n",
      "Ep 1 (Step 000465): Train loss 0.461, Val loss 0.872\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the chemical formula for carbon monoxide?\n",
      "Ep 2 (Step 000470): Train loss 0.545, Val loss 0.870\n",
      "Ep 2 (Step 000475): Train loss 0.491, Val loss 0.870\n",
      "Ep 2 (Step 000480): Train loss 0.437, Val loss 0.878\n",
      "Ep 2 (Step 000485): Train loss 0.371, Val loss 0.889\n",
      "Ep 2 (Step 000490): Train loss 0.503, Val loss 0.883\n",
      "Ep 2 (Step 000495): Train loss 0.534, Val loss 0.887\n",
      "Ep 2 (Step 000500): Train loss 0.504, Val loss 0.883\n",
      "Ep 2 (Step 000505): Train loss 0.474, Val loss 0.890\n",
      "Ep 2 (Step 000510): Train loss 0.457, Val loss 0.888\n",
      "Ep 2 (Step 000515): Train loss 0.595, Val loss 0.884\n",
      "Ep 2 (Step 000520): Train loss 0.514, Val loss 0.876\n",
      "Ep 2 (Step 000525): Train loss 0.452, Val loss 0.872\n",
      "Ep 2 (Step 000530): Train loss 0.456, Val loss 0.865\n",
      "Ep 2 (Step 000535): Train loss 0.552, Val loss 0.861\n",
      "Ep 2 (Step 000540): Train loss 0.558, Val loss 0.849\n",
      "Ep 2 (Step 000545): Train loss 0.506, Val loss 0.846\n",
      "Ep 2 (Step 000550): Train loss 0.505, Val loss 0.842\n",
      "Ep 2 (Step 000555): Train loss 0.571, Val loss 0.846\n",
      "Ep 2 (Step 000560): Train loss 0.519, Val loss 0.855\n",
      "Ep 2 (Step 000565): Train loss 0.448, Val loss 0.870\n",
      "Ep 2 (Step 000570): Train loss 0.484, Val loss 0.871\n",
      "Ep 2 (Step 000575): Train loss 0.481, Val loss 0.876\n",
      "Ep 2 (Step 000580): Train loss 0.550, Val loss 0.881\n",
      "Ep 2 (Step 000585): Train loss 0.571, Val loss 0.906\n",
      "Ep 2 (Step 000590): Train loss 0.419, Val loss 0.875\n",
      "Ep 2 (Step 000595): Train loss 0.457, Val loss 0.860\n",
      "Ep 2 (Step 000600): Train loss 0.405, Val loss 0.852\n",
      "Ep 2 (Step 000605): Train loss 0.503, Val loss 0.855\n",
      "Ep 2 (Step 000610): Train loss 0.336, Val loss 0.862\n",
      "Ep 2 (Step 000615): Train loss 0.591, Val loss 0.866\n",
      "Ep 2 (Step 000620): Train loss 0.425, Val loss 0.870\n",
      "Ep 2 (Step 000625): Train loss 0.405, Val loss 0.871\n",
      "Ep 2 (Step 000630): Train loss 0.518, Val loss 0.868\n",
      "Ep 2 (Step 000635): Train loss 0.297, Val loss 0.878\n",
      "Ep 2 (Step 000640): Train loss 0.420, Val loss 0.891\n",
      "Ep 2 (Step 000645): Train loss 0.462, Val loss 0.877\n",
      "Ep 2 (Step 000650): Train loss 0.445, Val loss 0.872\n",
      "Ep 2 (Step 000655): Train loss 0.340, Val loss 0.875\n",
      "Ep 2 (Step 000660): Train loss 0.541, Val loss 0.880\n",
      "Ep 2 (Step 000665): Train loss 0.326, Val loss 0.888\n",
      "Ep 2 (Step 000670): Train loss 0.395, Val loss 0.900\n",
      "Ep 2 (Step 000675): Train loss 0.454, Val loss 0.912\n",
      "Ep 2 (Step 000680): Train loss 0.422, Val loss 0.913\n",
      "Ep 2 (Step 000685): Train loss 0.460, Val loss 0.901\n",
      "Ep 2 (Step 000690): Train loss 0.481, Val loss 0.882\n",
      "Ep 2 (Step 000695): Train loss 0.488, Val loss 0.876\n",
      "Ep 2 (Step 000700): Train loss 0.439, Val loss 0.879\n",
      "Ep 2 (Step 000705): Train loss 0.399, Val loss 0.877\n",
      "Ep 2 (Step 000710): Train loss 0.417, Val loss 0.866\n",
      "Ep 2 (Step 000715): Train loss 0.541, Val loss 0.858\n",
      "Ep 2 (Step 000720): Train loss 0.488, Val loss 0.855\n",
      "Ep 2 (Step 000725): Train loss 0.497, Val loss 0.852\n",
      "Ep 2 (Step 000730): Train loss 0.419, Val loss 0.856\n",
      "Ep 2 (Step 000735): Train loss 0.408, Val loss 0.863\n",
      "Ep 2 (Step 000740): Train loss 0.390, Val loss 0.869\n",
      "Ep 2 (Step 000745): Train loss 0.344, Val loss 0.879\n",
      "Ep 2 (Step 000750): Train loss 0.304, Val loss 0.888\n",
      "Ep 2 (Step 000755): Train loss 0.320, Val loss 0.881\n",
      "Ep 2 (Step 000760): Train loss 0.409, Val loss 0.854\n",
      "Ep 2 (Step 000765): Train loss 0.354, Val loss 0.838\n",
      "Ep 2 (Step 000770): Train loss 0.396, Val loss 0.821\n",
      "Ep 2 (Step 000775): Train loss 0.418, Val loss 0.815\n",
      "Ep 2 (Step 000780): Train loss 0.335, Val loss 0.823\n",
      "Ep 2 (Step 000785): Train loss 0.485, Val loss 0.830\n",
      "Ep 2 (Step 000790): Train loss 0.368, Val loss 0.833\n",
      "Ep 2 (Step 000795): Train loss 0.356, Val loss 0.835\n",
      "Ep 2 (Step 000800): Train loss 0.385, Val loss 0.836\n",
      "Ep 2 (Step 000805): Train loss 0.364, Val loss 0.830\n",
      "Ep 2 (Step 000810): Train loss 0.500, Val loss 0.824\n",
      "Ep 2 (Step 000815): Train loss 0.514, Val loss 0.818\n",
      "Ep 2 (Step 000820): Train loss 0.320, Val loss 0.818\n",
      "Ep 2 (Step 000825): Train loss 0.427, Val loss 0.818\n",
      "Ep 2 (Step 000830): Train loss 0.389, Val loss 0.810\n",
      "Ep 2 (Step 000835): Train loss 0.447, Val loss 0.808\n",
      "Ep 2 (Step 000840): Train loss 0.360, Val loss 0.812\n",
      "Ep 2 (Step 000845): Train loss 0.391, Val loss 0.817\n",
      "Ep 2 (Step 000850): Train loss 0.378, Val loss 0.821\n",
      "Ep 2 (Step 000855): Train loss 0.343, Val loss 0.830\n",
      "Ep 2 (Step 000860): Train loss 0.338, Val loss 0.842\n",
      "Ep 2 (Step 000865): Train loss 0.476, Val loss 0.846\n",
      "Ep 2 (Step 000870): Train loss 0.455, Val loss 0.826\n",
      "Ep 2 (Step 000875): Train loss 0.374, Val loss 0.813\n",
      "Ep 2 (Step 000880): Train loss 0.310, Val loss 0.813\n",
      "Ep 2 (Step 000885): Train loss 0.322, Val loss 0.814\n",
      "Ep 2 (Step 000890): Train loss 0.397, Val loss 0.813\n",
      "Ep 2 (Step 000895): Train loss 0.402, Val loss 0.810\n",
      "Ep 2 (Step 000900): Train loss 0.362, Val loss 0.809\n",
      "Ep 2 (Step 000905): Train loss 0.284, Val loss 0.813\n",
      "Ep 2 (Step 000910): Train loss 0.374, Val loss 0.808\n",
      "Ep 2 (Step 000915): Train loss 0.384, Val loss 0.806\n",
      "Ep 2 (Step 000920): Train loss 0.408, Val loss 0.805\n",
      "Ep 2 (Step 000925): Train loss 0.251, Val loss 0.804\n",
      "Ep 2 (Step 000930): Train loss 0.279, Val loss 0.806\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: Ingredients for the cake: Milk, eggs\n",
      "Training completed in 7.51 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9d0c329-e290-44a2-9a1a-89f0ca63f112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:23:53.850012Z",
     "iopub.status.busy": "2025-03-30T22:23:53.849503Z",
     "iopub.status.idle": "2025-03-30T22:23:54.033638Z",
     "shell.execute_reply": "2025-03-30T22:23:54.033302Z",
     "shell.execute_reply.started": "2025-03-30T22:23:53.849970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chap5 import plot_losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08388abc-1b13-4b7d-a36e-4e9deef551fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:29:55.972820Z",
     "iopub.status.busy": "2025-03-30T22:29:55.971957Z",
     "iopub.status.idle": "2025-03-30T22:29:58.405162Z",
     "shell.execute_reply": "2025-03-30T22:29:58.404586Z",
     "shell.execute_reply.started": "2025-03-30T22:29:55.972775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is cirrus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is John Stuart Mill.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:      #1\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(               #2\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "128db0df-9223-42a6-9dc0-4bbe403cfc78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:39:31.442809Z",
     "iopub.status.busy": "2025-03-30T22:39:31.442288Z",
     "iopub.status.idle": "2025-03-30T22:42:21.617321Z",
     "shell.execute_reply": "2025-03-30T22:42:21.617056Z",
     "shell.execute_reply.started": "2025-03-30T22:39:31.442767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [02:50<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)         #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "408d1927-a72c-4296-a89c-3953dc689a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:42:21.617851Z",
     "iopub.status.busy": "2025-03-30T22:42:21.617711Z",
     "iopub.status.idle": "2025-03-30T22:42:21.641259Z",
     "shell.execute_reply": "2025-03-30T22:42:21.640929Z",
     "shell.execute_reply.started": "2025-03-30T22:42:21.617843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5acec00-e8c9-4af8-9a4e-6ee8c31a0237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:42:21.641670Z",
     "iopub.status.busy": "2025-03-30T22:42:21.641548Z",
     "iopub.status.idle": "2025-03-30T22:42:22.122222Z",
     "shell.execute_reply": "2025-03-30T22:42:22.121710Z",
     "shell.execute_reply.started": "2025-03-30T22:42:21.641662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as /work/tmp/gpt2/gpt2-small124M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"/work/tmp/gpt2/{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"      #1\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2c8ada-8af2-4244-a960-180e453d55ad",
   "metadata": {},
   "source": [
    "# Test framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd0535-f7b7-4745-bd00-bd0de3b34fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:53:44.221114Z",
     "iopub.status.busy": "2025-03-30T22:53:44.220717Z",
     "iopub.status.idle": "2025-03-30T22:53:44.223130Z",
     "shell.execute_reply": "2025-03-30T22:53:44.222702Z",
     "shell.execute_reply.started": "2025-03-30T22:53:44.221103Z"
    }
   },
   "source": [
    "### The follow code bellow will not work properly from inside a container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac85879-c694-43e2-ac6f-80744cf56517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:53:47.817922Z",
     "iopub.status.busy": "2025-03-30T22:53:47.817430Z",
     "iopub.status.idle": "2025-03-30T22:53:47.844852Z",
     "shell.execute_reply": "2025-03-30T22:53:47.844145Z",
     "shell.execute_reply.started": "2025-03-30T22:53:47.817881Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Ollama not running. Launch ollama before proceeding.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m ollama_running \u001b[38;5;241m=\u001b[39m check_if_running(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ollama_running:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama not running. Launch ollama before proceeding.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama running:\u001b[39m\u001b[38;5;124m\"\u001b[39m, check_if_running(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Ollama not running. Launch ollama before proceeding."
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        \"Ollama not running. Launch ollama before proceeding.\"\n",
    ")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e570724-3674-4a2f-baf8-015a3d15084e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:54:22.586937Z",
     "iopub.status.busy": "2025-03-30T22:54:22.586395Z",
     "iopub.status.idle": "2025-03-30T22:54:22.601228Z",
     "shell.execute_reply": "2025-03-30T22:54:22.600297Z",
     "shell.execute_reply.started": "2025-03-30T22:54:22.586891Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c0f0df4-572c-4a68-afcd-0533438d0cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:01:05.516761Z",
     "iopub.status.busy": "2025-03-30T23:01:05.516273Z",
     "iopub.status.idle": "2025-03-30T23:01:05.525727Z",
     "shell.execute_reply": "2025-03-30T23:01:05.523798Z",
     "shell.execute_reply.started": "2025-03-30T23:01:05.516723Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(prompt, model=\"gemma3:1b\", url=\"http://192.168.0.123:11434/api/chat\"):\n",
    "    data = {             #1\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {         #2\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "    payload = json.dumps(data).encode(\"utf-8\")    #3\n",
    "    request = urllib.request.Request(                       #4\n",
    "        url,                                                #4\n",
    "        data=payload,                                       #4\n",
    "        method=\"POST\"                                       #4\n",
    "    ) #4\n",
    "\n",
    "    request.add_header(\"Content-Type\", \"application/json\")   #4\n",
    "\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:   #5\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791232f6-0155-4ee3-944a-0abfc02c6cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:01:13.210938Z",
     "iopub.status.busy": "2025-03-30T23:01:13.210447Z",
     "iopub.status.idle": "2025-03-30T23:01:26.927881Z",
     "shell.execute_reply": "2025-03-30T23:01:26.927286Z",
     "shell.execute_reply.started": "2025-03-30T23:01:13.210898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are surprisingly versatile herbivores and have a pretty varied diet! Here's a breakdown of what they typically eat:\n",
      "\n",
      "**1. The Majority - Grass & Forage:**\n",
      "\n",
      "* **Grass:** This is their primary food source, especially in the western United States and parts of South America. They'll graze on a wide variety of grasses.\n",
      "* **Forage:** They love foraged plants, including:\n",
      "    * **Acorns:** A staple in many llama habitats.\n",
      "    * **Shrubs & Bushes:** They'll nibble on various shrubs and bushes.\n",
      "    * **Wild Berries & Fruits:** They'll eat wild berries and fruits when available.\n",
      "    * **Leaves & Twigs:** They'll consume leaves and twigs, especially in the spring and summer.\n",
      "\n",
      "\n",
      "**2. Supplementation - What They Eat When Available:**\n",
      "\n",
      "* **Hay:** Llamas need hay to supplement their diet, especially during the winter months when grass is scarce.\n",
      "* **Pasture:** They graze on pasture, supplementing their diet with fresh vegetation.\n",
      "* **Vegetables:**  They'll eat vegetables like:\n",
      "    * **Carrots:** A favorite.\n",
      "    * **Sweet Potatoes:**  A nutritious and tasty treat.\n",
      "    * **Leafy Greens:** Kale, spinach, and other greens.\n",
      "* **Fruits:**  They'll eat fruits like apples, pears, and berries.\n",
      "\n",
      "\n",
      "**3.  Specific Dietary Needs & Considerations:**\n",
      "\n",
      "* **Fiber is Key:** Llamas need a good amount of fiber to maintain their digestive health.\n",
      "* **Water:**  They need access to fresh, clean water at all times.\n",
      "* **Variety is Important:**  A balanced diet with a mix of grasses, foraged plants, and supplemental foods is crucial for their well-being.\n",
      "\n",
      "\n",
      "**Important Note:**  Llamas are social animals and often graze together.  Their diet is influenced by the availability of food in their environment.\n",
      "\n",
      "\n",
      "Do you want to know more about a specific aspect of llama nutrition, like their digestive system or how they find food?\n"
     ]
    }
   ],
   "source": [
    "result = query_model(\"What do Llamas eat?\", 'gemma3:1b')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffa3b49-7103-447b-89d0-a332761823ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:01:36.516139Z",
     "iopub.status.busy": "2025-03-30T23:01:36.515614Z",
     "iopub.status.idle": "2025-03-30T23:01:36.523114Z",
     "shell.execute_reply": "2025-03-30T23:01:36.522059Z",
     "shell.execute_reply.started": "2025-03-30T23:01:36.516097Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"   #1\n",
    "        )\n",
    "        score = query_model(prompt)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf04f58-bc5d-4fd6-8212-3e29b0630c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:01:37.906341Z",
     "iopub.status.busy": "2025-03-30T23:01:37.905846Z",
     "iopub.status.idle": "2025-03-30T23:02:44.162061Z",
     "shell.execute_reply": "2025-03-30T23:02:44.161681Z",
     "shell.execute_reply.started": "2025-03-30T23:01:37.906302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   9%|         | 10/110 [00:05<01:07,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Prime numbers: 11, 19\n",
      "Composite numbers: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  15%|        | 16/110 [00:09<00:56,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Plants: Solid\n",
      "Animals: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  18%|        | 20/110 [00:12<01:34,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Never have I ever seen a sunset like this without a warm cup of tea.\n",
      "Score: 95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  21%|        | 23/110 [00:14<01:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The opposite of 'deep' is 'shallow'. 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  41%|      | 45/110 [00:26<00:35,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 95\n",
      "\n",
      "Score: 95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  43%|     | 47/110 [00:27<00:39,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Could you tell me the meeting time?\n",
      "\n",
      "Score: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  55%|    | 61/110 [00:35<00:25,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: young\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  61%|    | 67/110 [00:38<00:26,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Did the dog chase the cat?\n",
      "Score: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  78%|  | 86/110 [00:49<00:15,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The professor attempted to elucidate the complex topic for his students.  95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  83%| | 91/110 [00:53<00:12,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The food was delicious.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  84%| | 92/110 [00:54<00:13,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The opposite of 'lazy' is 'diligent'.\n",
      "Score: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  85%| | 93/110 [00:55<00:14,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 1. Vitamin A\n",
      "2. Vitamin C\n",
      "3. Vitamin D\n",
      "Score: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [01:06<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 32.07\n",
      "\n",
      "Number of scores: 97 of 110\n",
      "Average score: 82.47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ec7d0-2bed-48a7-af61-dbc9e9e3b00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:05:43.147743Z",
     "iopub.status.busy": "2025-03-30T23:05:43.147242Z",
     "iopub.status.idle": "2025-03-30T23:05:43.154152Z",
     "shell.execute_reply": "2025-03-30T23:05:43.152710Z",
     "shell.execute_reply.started": "2025-03-30T23:05:43.147706Z"
    }
   },
   "source": [
    "# Using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "960fa976-6b03-465e-80ae-57e93dd70f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:08:01.975582Z",
     "iopub.status.busy": "2025-03-30T23:08:01.974572Z",
     "iopub.status.idle": "2025-03-30T23:08:01.982273Z",
     "shell.execute_reply": "2025-03-30T23:08:01.980918Z",
     "shell.execute_reply.started": "2025-03-30T23:08:01.975523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/tmp/gpt2/gpt2-small124M-sft.pth'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"/work/tmp/gpt2/{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"  \n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a280b15-64a8-4bd7-94fb-7d8b3bf8db79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:08:36.887268Z",
     "iopub.status.busy": "2025-03-30T23:08:36.886494Z",
     "iopub.status.idle": "2025-03-30T23:08:37.006331Z",
     "shell.execute_reply": "2025-03-30T23:08:37.006018Z",
     "shell.execute_reply.started": "2025-03-30T23:08:36.887195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():   #1\n",
    "#     device = torch.device(\"mps\")\"      \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aa121a4-813c-4b22-843e-e57c28b702ef",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-30T23:17:10.592968Z",
     "iopub.status.busy": "2025-03-30T23:17:10.592406Z",
     "iopub.status.idle": "2025-03-30T23:17:11.126863Z",
     "shell.execute_reply": "2025-03-30T23:17:11.126505Z",
     "shell.execute_reply.started": "2025-03-30T23:17:10.592926Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='tanh')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(file_name, map_location=device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "689afc42-089f-43bd-817d-f53abe50ce79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:27:37.799114Z",
     "iopub.status.busy": "2025-03-30T23:27:37.798615Z",
     "iopub.status.idle": "2025-03-30T23:27:37.805333Z",
     "shell.execute_reply": "2025-03-30T23:27:37.803946Z",
     "shell.execute_reply.started": "2025-03-30T23:27:37.799077Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "from chap5 import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "def query_model_our_model(prompt):\n",
    "    model.eval()\n",
    "    encoded = text_to_token_ids(prompt, tokenizer).to(device)\n",
    "    logits = model(encoded)\n",
    "    idx_next = torch.argmax(logits, dim=-1, keepdim=True).squeeze(0).transpose(0,1)\n",
    "    response_data = token_ids_to_text(idx_next, tokenizer).replace('<|endoftext|>', '')\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e948d155-e147-4fb7-8988-b5e75e23fd71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:27:38.433960Z",
     "iopub.status.busy": "2025-03-30T23:27:38.433455Z",
     "iopub.status.idle": "2025-03-30T23:27:38.491355Z",
     "shell.execute_reply": "2025-03-30T23:27:38.490865Z",
     "shell.execute_reply.started": "2025-03-30T23:27:38.433921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' is please me what formula was of\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_model_our_model('Could you tell me the meeting time?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e089e68f-5360-443a-b7bd-7844e2158e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:27:39.925806Z",
     "iopub.status.busy": "2025-03-30T23:27:39.925300Z",
     "iopub.status.idle": "2025-03-30T23:27:39.969437Z",
     "shell.execute_reply": "2025-03-30T23:27:39.968791Z",
     "shell.execute_reply.started": "2025-03-30T23:27:39.925770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is youazyas mean?\n"
     ]
    }
   ],
   "source": [
    "result = query_model_our_model(\"What do Llamas eat?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ac36271-d08a-4985-81fb-47a80363bf4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:27:41.151272Z",
     "iopub.status.busy": "2025-03-30T23:27:41.150753Z",
     "iopub.status.idle": "2025-03-30T23:27:41.158612Z",
     "shell.execute_reply": "2025-03-30T23:27:41.157182Z",
     "shell.execute_reply.started": "2025-03-30T23:27:41.151219Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_model_scores_our_model(json_data, json_key):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"   #1\n",
    "        )\n",
    "        score = query_model_our_model(prompt)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "205b7af4-3966-4b85-b707-7d5b190795c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:27:43.590642Z",
     "iopub.status.busy": "2025-03-30T23:27:43.590084Z",
     "iopub.status.idle": "2025-03-30T23:27:50.349670Z",
     "shell.execute_reply": "2025-03-30T23:27:50.349139Z",
     "shell.execute_reply.started": "2025-03-30T23:27:43.590603Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   2%|         | 2/110 [00:00<00:14,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence using a metaphorile.\n",
      "\n",
      "### Input:\n",
      "She wind is very fast.\n",
      "\n",
      " the response:The car is as fast as a.\n",
      ": correct..The car is as fast as a bullet.\n",
      " the bullet of 1 to 100. positive 100 is very normal possible,\n",
      "ing the appropriate result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is of compound is formed seen with the??\n",
      "\n",
      "\n",
      " answers:The type of cloud is associated with thunderstorms is aulusonimbus.\n",
      ": correct correctly.The type of cloud typically associated with thunderstorms is cumrus.`. a 10 of 1 to 10. positive 1 is normal normal,.\n",
      "ing a model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the process of theTheide and Prejudice'.\n",
      "\n",
      " ' me:Pr Austen'.\n",
      ": sentence.' `Pr model of 'Pride and Prejudice' is Jane Aust Mill.\n",
      " behalf computer of 0 to 10. 100 a is neutral normal score.ing appropriate model result 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   5%|         | 6/110 [00:00<00:07, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for the?\n",
      "\n",
      "\n",
      " the:0 periodic symbol for chlorine is CH.\n",
      ": correct correctly appropriatelyCl periodic symbol for chlorine is C.`. a 10 of 1 to 9. positive 0 is neutral periodic,,\n",
      "ing a model value 10 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the spellinguation in the sentence.\n",
      "\n",
      "### Input:\n",
      "The raining to go to.\n",
      "\n",
      "\n",
      " the:Where time sentence is be: 'It's time to go home.'\n",
      "\n",
      ": corrected:.The corrected sentence should be: 'It's time to go home.' the scale of 1 to 10. positive 1 is perfect normal.. to the correct result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence using\n",
      "\n",
      "### Input:\n",
      "The sun was given by French calm and.\n",
      "\n",
      "\n",
      " grammar:The lecture was delivered in.'\n",
      ": given..The model was delivered in a clear manner.\n",
      " the computer of 1 to 10. positive a is perfect best,,ing a appropriate result 10 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence sentence about\n",
      "\n",
      "\n",
      " any:She is the cat teacher given?\n",
      " it was a much words?\n",
      ": sentence a.Correct model anecdote was: 'The was the.' the scale of 1 to 10. positive 100 is neutral highest score.ing the appropriate result 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   9%|         | 10/110 [00:00<00:06, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the main spelling of 'Theieve'\n",
      " 'recceive.'\n",
      "\n",
      " ' spelling:Rec correct spelling is 'recceive'.\n",
      ": request::The model spelling is 'reieve'.` a scale of 1 to 10. positive 1 is perfect normal,, to the spelling result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What a new that the word 'darrowalgia'.\n",
      "\n",
      "\n",
      " the:Theostalgia is over the.' she went at the window store'.\n",
      ": correct`.The model photos was 'wostalgia' was ' synonym for 'wear'.\n",
      " July syn of 1 to 10. positive a is very past,.ing the correct result 10 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the following statement as prime or composite.\n",
      "\n",
      "### Input:\n",
      "1 3, 15, 15,\n",
      "\n",
      " 20 answers:: numbers: 11, 19,\n",
      "posite numbers: 19, 19: given..Here numbers: 11, 19 19. the scale of composite to 9. 100 ' is prime normal..ing the model form 11.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of the?\n",
      "\n",
      "\n",
      " the:D capital of Denmark is Copenhagen.'\n",
      ": correct correctly.Correct capital of Denmark is CopenhagenAN. 8 10 of 1 to 10. positive 100 is neutral capital,.\n",
      ": a model result 100 `\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  13%|        | 14/110 [00:00<00:05, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of 'smallonder'?\n",
      "\n",
      " ' the:Below opposite of 'wet' is 'dry'.\n",
      "\n",
      ": correct correctly.0 model of 'dryet' is 'dry'.` 12 model of 1 to 10. positive a is warm normal,, to ' model result 100 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the main of sentence.\n",
      "\n",
      "### Input:\n",
      "The you know your homework?\n",
      "\n",
      "\n",
      " the:Did type of sentence is 'ative.\n",
      ": correct..The type of sentence is interrog.\n",
      " the dependent of 1 to 10. positive 100 is interrog most..ing the model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for iron?\n",
      "\n",
      "\n",
      " the:C2' corrected: correct correctly appropriatelyC chemical symbol for mercury is Mercuryg.\n",
      " a 10 of 0 to 10. where 0 is pure normal,,\n",
      ": a model result 10 `\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatribe the process of combustion cooling. terms.\n",
      "\n",
      " ` the:Trans transport is the process of cells between the liquid membrane. cell cell of active concentration to a region of higher concentration. where a stored the cell of heat.\n",
      " process is called for cell cell healthostasis.\n",
      "\n",
      ": correct cell.Transport is the movement of active of molecules from regions regions of the cell. the cell of 0 to 10. where 100 is neutral normal,.ing the model response 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  16%|        | 18/110 [00:01<00:05, 17.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the following statement: either food or liquid, or gas.\n",
      "\n",
      "### Input:\n",
      "Iceury\n",
      " Iron, iron\n",
      "\n",
      " ' the:Plury` Solid'\n",
      "xygen - Solid\n",
      "Pl - Solid\n",
      " Input: given accurately.Plants - Mercury,Anim: Oxy\n",
      "Oals: Squirrel model table of solid to 10 from ' is solid solid\n",
      ": the model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the lit to meters.\n",
      "\n",
      "\n",
      " the:3 kilometers is 3000 meters.\n",
      "\n",
      ": correct correct.3 kilometers is 3000 meters'.\n",
      " a scale of 0 to 100. positive 0 is normal square,,\n",
      " with a correct result 3 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the given to use a indefinite pronoun:\n",
      "\n",
      "### Input:\n",
      "She was a message.\n",
      "\n",
      " she the:She note was left by someone.\n",
      ": correct..Correct left a note.\n",
      " the computer of 1 to 10. positive 1 is perfect smallest,.\n",
      ": the given result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatide a synonym for 'beautiting'.\n",
      "\n",
      " ' the:Exc synonym for 'excited' is 'excrilling'.\n",
      "\n",
      ": sentence..Here synonym for 'excited' is 'thiting'.` 12 syn of 1 to 10. positive ' is very highest,, to ` model result 100 `\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  20%|        | 22/110 [00:01<00:06, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that follows the pattern: 'The miss felt seen been_____\" it_____.\"\n",
      "\n",
      " \" the:I have I ever without without   without\n",
      "\n",
      ": correct correctly.The have I ever traveled a  a a.' had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had had the map of 0 to 10. where 100 is the normal..\n",
      " to the sentence result of:\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the the correct from the sentence sentence.\n",
      "\n",
      "### Input:\n",
      "The, mountain, blue\n",
      "\n",
      " clean\n",
      ":He adjective adjective from the list is 'run'.\n",
      "\n",
      ": sentence:.Run model from the list is 'run.'`.\n",
      " the scale of 1 to 10. positive ' is perfect square..\n",
      ": the correct result 10 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the grams to kilograms.\n",
      "\n",
      "\n",
      " the:1000 grams is 0 to 0 kgogram.\n",
      "\n",
      ": correct 100.1000 grams is equal.9 kilograms. the scale of 0 to 9. 1 0 is negative square,.\n",
      " with the correct result 1000 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of 'small'?\n",
      "\n",
      " ' the:Deep opposite of 'deep' is 'deepining'.\n",
      "\n",
      ": correct correctly.Deep opposite of 'deep' is 'lighteeper'.` 12 scale of 1 to 10. positive 1 is shallow normal,, to ' model result 100 `\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  24%|       | 26/110 [00:01<00:05, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatategorize the given numbers of animals.\n",
      "\n",
      "### Input:\n",
      "Bearark\n",
      " Elephant, Elephant\n",
      "\n",
      " Elephant the:Here, Shark, Dolphin`\n",
      "inerals: Dolphin\n",
      " Shark: given::Fishals: DolphinFals: Dolphin the scale of 1 to 10 from ' is perfect best..: the model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where' into French.\n",
      "\n",
      " ' Spanish:Here Spanish translation for 'library' is 'liblioteca'.\n",
      "\n",
      ": translation..The Spanish word of 'library' is 'b b estos'.os'. Julyria of 1 to 10. 1 1 is neutral best score. to a model result 3 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatine the term 'quantbole'.\n",
      "\n",
      " ` any:Herebole' a hyper of speech in describes a ex of a or the purpose of exaggeration.\n",
      ": correct a.Thebole is a metaphor of hyper that typically typically used to describe a humorous's behavior or manner of speaking. a computer of 1 to 10. positive a is very normal,, to ` model form 5 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where' into Japanese.\n",
      "\n",
      " ' the:Hereravz)'  corrected: correct '.P model model of 'The' is '' (P) \n",
      "\n",
      " July computer of 1 to 10. 1 1 is perfect best,,\n",
      "ing the correct result 100:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  27%|       | 30/110 [00:01<00:04, 17.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatine the term 'quantetic'.'.\n",
      "\n",
      " ` any:Hereetic energy' the total that is object is that to its being,\n",
      ": correct `.0 model 'kinetic energy' is ' type of energy that is generated by a process's movement body. is typically expressed in terms of a type of electromagnetic field. the scale of 0 to 10. positive 0 is neutral mass,.ing the model result 10 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of 'small'?\n",
      "\n",
      " ' the:Below opposite of 'hot' is 'cold'.\n",
      "\n",
      ": correct correctly.0 model of 'hot' is 'cold'.` 12 10 of 0 to 10. positive 1 is neutral normal,,\n",
      " to ' model result 100 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the kilometers per kilometers per\n",
      "\n",
      " 15 the:5 miles is 5 5.5 kilometers.\n",
      "\n",
      ": correct at:5 miles is approximately..\n",
      " the scale of 0 to 100. 1 0 is very square,,\n",
      " with the correct result 5:\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chlorideate?\n",
      "\n",
      "\n",
      " the:M chemical formula for magnesium sulfate is MgS4.\n",
      "\n",
      ": correct correctly,M model formula for magnesium sulfate is MgSO6.` a 10 of 0 to 10. and 0 is pure normal,.\n",
      ": a model result 100.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  31%|       | 34/110 [00:02<00:04, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence sentence to use the active with with\n",
      "\n",
      "### Input:\n",
      "She's hot cold of cake.\n",
      " everyone the:It's a tasty to\n",
      "rs cake`.Easy\n",
      "###'s a cake of cake. the piece of 1 to 10. positive 1 is perfect smallest,.ing a appropriate result 3 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the types types of flowers\n",
      "\n",
      "\n",
      "\n",
      " the:Ve. Brorot'2. Broccoli\n",
      "3. Broucumber\n",
      "4. Tomato\n",
      "5. Basilach\n",
      " corrected: correct::1. Carccoli\n",
      "6. Carccoli3. Tomatoccoli4. Tomatoccoli5. Spinccoli the scale of 1 to 10 100 100 is perfect smallest\n",
      ".ing the model result 5.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the meters to meters.\n",
      "\n",
      "\n",
      " the:7 kilometers is 7 meters.\n",
      "\n",
      ": correct correct.7 kilometers is 6000000.\n",
      " the scale of 1 to 100. positive 0 is normal square score.\n",
      " with a correct result 7:\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of 'small'?\n",
      "\n",
      " ' the:heavy opposite of 'heavy' is 'light'.\n",
      "\n",
      ": correct..0 opposite of 'heavy' is 'heavy'.` 12 scale of 1 to 10. positive 1 is very normal,. to ' model result 5 `\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  35%|      | 38/110 [00:02<00:03, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical tense of 'buildular\n",
      "\n",
      " ' me:Here past tense of 'sing' is 'pastang'. corrected: correct correctly.The past tense of 'sing' is 's.' the continuous of 1 to 10. positive ' is perfect past.. to ' correct ' 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for the??\n",
      "\n",
      "\n",
      " the:0 molecular formula for carbon dioxide is CH2.\n",
      "\n",
      ": correct correctly.Correct molecular formula for carbon dioxide is CH3. a 10 of 1 to 9. where 1 is neutral normal,.\n",
      ": a model result 10.\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the sentence to use voice:\n",
      "\n",
      " Input:\n",
      "The chefener is the plants.\n",
      "\n",
      " the the:The plants watered watered by the gardener.\n",
      "\n",
      ": correct..The plants were by plants by\n",
      " the continuous of 1 to 10. positive 100 is normal highest,.\n",
      ": passive model result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical tense of 'build'?\n",
      "\n",
      " ' the:Here past tense of 'throw' is 'drew'.\n",
      "\n",
      ": given..The past tense of 'throw' is 'th'.` the continuous of 1 to 10. positive 1 is neutral past.. to ' correct result 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  38%|      | 42/110 [00:02<00:03, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatain the a synogram is.\n",
      "\n",
      " ` any:He sonnet is a son-digit cell. a rhy rhythmme scheme. a. typically ' in the.ic pentateter.\n",
      "\n",
      ": correct::The sonnet is a 12 for measures the length of a child's body. the base of the or her feet to the base of his or her legs's a 7 of 1 to 10. 1 100 is perfect smallest,.\n",
      " to the model result 0:\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that the word 'dovative'.\n",
      "\n",
      " ` the:The project is developing for innovative innovative ideas and\n",
      ": correct a.The company was inspired by its company of the team manager. the computer of 1 to 10. positive 100 is innovative highest,.\n",
      "ing the sentence result 10 100\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatide a correct form of 'tourious'.\n",
      "\n",
      " ' the:c plural form of 'cactus' is 'cactusi'.\n",
      "\n",
      ": sentence `.The plural form of 'cactus' is 'cactus'.` lineria of 1 to 10. 1 1 is neutral normal,, to ' model form 3 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate ' sentence 'Where is the nearest?' into Japanese.\n",
      "The ' the:Where bathroom translation of 'Where is the bathroom?' is 'D t  Entchte  corrected: correct a.The German model of 'Where is the bathroom?' is 'Was gegen '. request request of 1 to 10. 100 1 is perfect normal translation,ing a correct result 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  42%|     | 46/110 [00:02<00:03, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence-tense verb that follows a person who.\n",
      "\n",
      " ' the:Sheaughter at` corrected: sentence a.C past-tense verb that describes a person laughing is 'Curious'.` 12ria of 1 to 10. positive a is very normal,,ing the correct result 5:\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that the word 'dcend'.\n",
      "\n",
      " ` the:Trans room was of the voice was a lasting impression on\n",
      "rs sentence a.Trans was very intelligent and helps helps others in need.` the scale of 1 to 10. positive 100 is very most,.\n",
      " with the sentence result 10 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that the word 'distic'.\n",
      "\n",
      " ` the:pl is optimistic about the setbacks.' faced.'\n",
      ": sentence..He was optimistic despite the future despite the scale of 1 to 10. positive 100 is optimistic most,,\n",
      " to the sentence result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What-write this sentence to a active voice.\n",
      "\n",
      "### Input:\n",
      "She is is it capital of\n",
      "\n",
      "\n",
      " question:The you please me the time is meeting is?'`\n",
      ": meeting:.Could meeting is at 9:00 PM. a Sunday of 0 to 10. positive 0 is perfect past..ing a model question 9 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  45%|     | 50/110 [00:03<00:03, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatategorize the given items into either command. statement command, or a actionclamation.\n",
      "\n",
      "### Input:\n",
      "I is cute day!\n",
      "\n",
      " '::Whatqu: corrected: given a.Beaut model wasThe a beautiful day!\"`. a statement.\n",
      " the question of 1 to 10. positive 1 is perfect perfect,,ing the given question 100 1\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of 'small'?\n",
      "\n",
      " ' the:Below opposite of 'rich' is 'poor'.\n",
      "\n",
      ": correct correctly.0 model of 'poor' is 'poor'.` average scale of 0 to 10. 100 ' is ' normal,, to ' model result 100 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the synonym for the given word.\n",
      "\n",
      "### Input:\n",
      "He by\n",
      " finish the.Endence`\n",
      ": given..Here the book`\n",
      "\n",
      "### modelonym for the given verb is 'beginning the syn of 1 to 10. positive 1 is perfect standard score.ing the model result 3 1\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the sentence sentence to make that punct nouns are spelled correctly.\n",
      "\n",
      "### Input:\n",
      "The sky were. song.\n",
      "\n",
      "\n",
      " the:The birds sings beautiful songs.\n",
      ": given..The birds sing beautiful songs. the cell of 1 to 10. positive 1 is perfect highest score,ing the given result 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  49%|     | 54/110 [00:03<00:03, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the given sentence into a command. 'should\"\n",
      "\n",
      "### Input:\n",
      "She can't me..\n",
      "\n",
      " ' the:Could you help me tomorrow?\n",
      ": correct..Could you help me tomorrow?`.\n",
      " the scale of 1 to 10. positive 100 is neutral normal score,\n",
      "ing ' correct result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the following statement: hammer, car, cat.\n",
      "\n",
      " ' the:Animicle: Horse,Mants: Rose\n",
      "Animals: Tiger corrected: correct..Animals: BicycleCorrectants: RoseCorrectals: RoseCorrectals: Bat the bicycle of 0 to 10 100 100 is perfect normal..: the model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatine the term 'quantrad'.\n",
      "\n",
      " ` any:Hereclad is derived metaphor of speech'. the the are typically to a a way as they meaning meaning is not from the speaker meaning. the words.\n",
      ": correct `.Herey is a figureonym for 'int'. 15 syn of 1 to 10. 100 a is neutral brightest,. to the model result 10 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where' into Japanese.\n",
      "\n",
      " ' the:Here German translation of 'Welcome' is 'D itommen z\n",
      "\n",
      ": correct '.The German model of 'Will' is 'Willas gegen us gegen'.`. 15im of 1 to 10000 100 1 is perfect normal translation,\n",
      " to ' model result 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  53%|    | 58/110 [00:03<00:02, 17.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatain the process function of the human nervous.\n",
      "\n",
      "\n",
      " any:Here primary function of the human heart is to supply blood to the body and to oxygen and nutrients to the, to toxins dioxide from water substances from It\n",
      ": correct..The primary function of the human heart is to pump blood and the body, to remove blood to the tissues and to remove heat signals from the body.` the continuous of 1 to 10. positive 1 is normal normal,.ing the model result 10 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence sentence to use past tense.\n",
      "\n",
      "### Input:\n",
      "The is very a book. by the past's\n",
      "\n",
      "\n",
      " the:He is be reading a novel inspired by his grandmother.' corrected: correct sentence.He will reading a novel inspired by his grandmother. the future of 1 to 10. positive 100 is perfect normal,.ing the correct result 3 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the given sentence to a voice.\n",
      "\n",
      "### Input:\n",
      "She chef enforcement changed by the citizens.\n",
      "\n",
      "\n",
      " as:The government passed the law.'\n",
      ": correct..The government passed the law.'\n",
      " the continuous of 1 to 100. positive 100 is perfect law,,\n",
      "ing active given result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What a new that the word 'dvitable'.\n",
      "\n",
      "\n",
      " the:The project was inevitable due the circumstances.'\n",
      ": correct a.The model was the company was inevitable due to poor management. the computer of 1 to 10. positive 100 is inevitable most,.\n",
      " to the correct result 10 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  56%|    | 62/110 [00:03<00:02, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatategorize the given items into either formal or fictional.prov.\n",
      "\n",
      "### Input:\n",
      "Theocolate is delicious best thing in\n",
      "\n",
      " ' response:Theuchion isbased'\n",
      ": sentence a.C best isThe best dessert is chocolate.\"`. factual on fact. the factual of 1 to 3. positive 100 is factual best,,ing the correct result 3.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the antonym of 'begin'?\n",
      "\n",
      " ` the:old'\n",
      "\n",
      " ` correct correctly.old. old antonym of 'old'. 'old is\n",
      " line model of 0 to 10. 100 ' is old past,,\n",
      "ing ` response result 100 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatide a synonym for 'beaut'.'.\n",
      "\n",
      " ' the:The synonym for 'hardworking' is 'learigent'.\n",
      "\n",
      ": correct a.Here synonym for 'dworking' is 'deng'.` the syn of 1 to 10000 100 a is very normal,, to ` model result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical point of water in Celsius?\n",
      "\n",
      "\n",
      " the:C boiling point of sulfur is 78.8 degrees Celsius.\n",
      ": correct correctly.0 boiling point of sulfur is 78114 degrees Celsius.`. the 10 of 0 to 10. 1 0 is neutral normal..\n",
      ": a correct result 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  60%|    | 66/110 [00:03<00:02, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical form of 'begin'?\n",
      "\n",
      " ' the:Here plural form of 'child' is 'child'.\n",
      "\n",
      ": given correctly.Here plural form of 'child' is 'children'.` line sem of 1 to 10. positive 1 is positive smallest,, to ' model result 100 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the antonym of 'beginacent'?\n",
      "\n",
      " ` the:Here antonym of 'complicated' is 'diff'.\n",
      "\n",
      ": correct correctly.An antonym of 'simpleicated' is 'simpleicult'. 12 success of 1 to 10. 100 100 is very normal,. to ' model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the types of water.\n",
      "\n",
      " ' the:1 three forms of water are salt,water, liquid (water) and gas (ice).\n",
      "\n",
      ": correct correctly.3 forms of water are solid, liquid, and gas. line scale of 1 to 10. positive 0 is solid normal,. to a model result 3 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence to a complete.\n",
      "\n",
      "### Input:\n",
      "She chef bark the ball.\n",
      "\n",
      " the the:The the cat chase the cat?'\n",
      ": cat dog.Yes model chased the cat.'\n",
      " the question of 1 to 10. positive 100 is pure smallest score,\n",
      "ing a correct result 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  64%|   | 70/110 [00:04<00:02, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the following sentence into two declarative sentences: 'The cat was very.' the.'\n",
      "\n",
      " '::The movie was long but Interesting was interesting but\n",
      ": movie..The movie was interesting. interesting.' the dependent of 1 to 10. 100 1 is best longest score.ing ' correct result 5 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the following statement: either, base, or salt.\n",
      "\n",
      "### Input:\n",
      "Ciqu juice\n",
      " waterap, Honey\n",
      "\n",
      " ' answers:Cid: Lemon juice\n",
      "Base: Soap\n",
      "Butral: Base Base: correct correct.Ac model as in the given sentence are acid, base, and neutral. the scale of 0 to 10. positive a is neutral normal..ing the model form 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the synonym for 'largeatisf'?\n",
      "\n",
      " '?:Here synonym for 'sad' is 'ss'.\n",
      "\n",
      ": sentence a.0 synonym for 'sad' is 'sad'. the syn of 1 to 10000 positive 1 is happy normal,, to ' model result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the grammar mistakes in the given sentence.\n",
      "\n",
      "### Input:\n",
      "The am to bread. baked.ar.\n",
      "\n",
      "\n",
      "\n",
      " any:I prefer homemade cookies to store bo cookies\n",
      ": correct a.I for homemade cookies: Apple, flour, eggs, milk, and sugar.\n",
      " the scale of 1 to 10. positive a is very highest,.ing a correct result 100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  67%|   | 74/110 [00:04<00:01, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that the word 'dcend'.\n",
      "\n",
      " ` the:Trans voice at the hotel was very and like only a few of days.'\n",
      ": sentence sentence.He was a active and helps helps others in need. the scale of 1 to 10. positive 100 is very most,.\n",
      " with the sentence result 10 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where am tired' into Japanese.\n",
      "\n",
      " ' the:I Italian translation of 'I am lost' is 'Il ao ' (Cal the). or 'Mi pio pero' (if female).\n",
      "\n",
      ": correct..Here Italian model of 'I am lost' is 'Miaos a la vita pi'. theria of 1 to 10. 100 1 is perfect normal translation,ing a given result 100:\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the sentence into either scientific report. a news.\n",
      "\n",
      "### Input:\n",
      "The is describes a for the a new.\n",
      "\n",
      "\n",
      " spelling:This document'. ': manual..Electric document`. the 3 of 1 to 10. positive 100 is the best,.\n",
      " with ' model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the following numbers in alphabet order.\n",
      "\n",
      "### Input:\n",
      "1, 20, 3, 3, 3,\n",
      " so as:Here, 8, 7, 2, 2,\n",
      " correct: following::Here correct, 2, 5, 3,\n",
      "### model is descending order is: 25, 8, 3, 3, 3, 3, 3, the scale of 1 to 10. 1 0 is positive normal,,ing the correct in 25:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  71%|   | 78/110 [00:04<00:01, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where you help a tea?' into French.\n",
      "\n",
      " 's:Jeorerto levous suoir-ux'ux'.'. corrected: correct..P model model of 'Can I have some water?' is 'P' water? plus proche?`. theusc of 1 to 10. 1 1 is neutral normal score.ing a correct result 100:\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What a newile using the word 'dke as snow\n",
      "\n",
      "\n",
      " the:The cold are as cold as ice'.\n",
      ": correct`.Her simile with a sim one fuzzy blanket chilly thing. a hot of 1 to 10. positive 1 is perfect normal,. with the correct result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the following statement as their grammatical categories: 'mer swim, calm\n",
      "\n",
      " fast.:swim` '\n",
      "Pliful: Adjective\n",
      "Quickly: Adverb corrected. correct..Sw model words are swimming by swimming classified as swimming swim swim or beautiful. Swim quick, quick the beach of 1 to 10. perfect 100 is perfect normal..ing the given 3 100:\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatculate the perimeter of a object with a mass of 10 kilograms per a volume of 5 cm meters.\n",
      "\n",
      "\n",
      " the:15 density of the object is 15./ cubic cmimeter.\n",
      "\n",
      ": correct accurately and3 density of the object is 15 grams per the 5 of 0 to 100. 1 1 is dense normal,. with a model result 5 `\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  75%|  | 82/110 [00:04<00:01, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemicalviation for 'begin of Science Administration'?\n",
      "\n",
      "\n",
      " the:Here abbreviation for 'Master of Business Administration' is '.\n",
      "\n",
      ": correct correctly.M modelviation for 'Master of Business Administration' is MBABAE\n",
      " line computer of 1 to 10. 100 a is perfect best,,ing ' model result 5 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the given sentence from decimal toals to 8.\n",
      "\n",
      " X the:I Roman ' is Roman numerals is 8.' corrected: correct::The number numerals are ' given number are 9.` the scale of 1 to 9. 100 ' is negative normal,. to the correct ' 9 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of 'smallizontal'?\n",
      "\n",
      " ` the:Below opposite of 'horizontal' is 'vertical'.\n",
      "\n",
      ": correct correctly.0 opposite of 'vertical' is 'vertical'.` line scale of 1 to 10. 100 1 is normal normal,, to ' model result 100 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where is I find a?' into French.\n",
      "\n",
      " 's:Where Italian translation of 'Where can I buy tickets?' is 'Vove se rendo'amlea? corrected: correct..The model model for 'Where can I buy tickets?' is 'Diellato v v vita?'. behalfria of 1 to 10. 100 a is perfect best translation,ing a given result 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  78%|  | 86/110 [00:05<00:01, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence sentence to use the actives with\n",
      "\n",
      "### Input:\n",
      "She is very fast as a cucumber.\n",
      "\n",
      "\n",
      " the:He was as cool as\n",
      ": sentence..He was as cool as a cucumber. the hot of 1 to 10. positive 100 is neutral normal..\n",
      "ing the correct result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the main subject in the sentence.\n",
      "\n",
      "### Input:\n",
      "The main barked loudly.\n",
      "\n",
      " the the:The main verb in the sentence is 'barked'.\n",
      "\n",
      ": sentence:.The main verb in the sentence is 'barked'.`. a dependent of 1 to 10. positive 100 is neutral normal..ing the model result 3 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that the word 'diteid'.\n",
      "\n",
      " ` the:She child was to solveidate the subject topic of the class. He\n",
      ": students.'.The was very and composed. She the scale of 1 to 10. indicating 100 is very calm,.\n",
      "ing the correct result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the spelling.\n",
      "\n",
      "### Input:\n",
      "He, my friends went to the park.\n",
      "\n",
      " ' the:We friend and I went to the store.'\n",
      ": correct..Model went to the store. buy food.\n",
      " the scale of 1 to 10. positive 1 is very most,,\n",
      "ing a correct result 5 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  82%| | 90/110 [00:05<00:01, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical for the the hours?\n",
      "\n",
      "\n",
      "??Here formula for calculating work done is (/ (/ volume.'\n",
      "\n",
      ": correct..The formula for calculating work done is work1  distance1/2) * distance1/2) * distance1/2) * distance1/2) + distance1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + (1/2) + ( the computer of 0 to 10. positive 100 is positive normal..\n",
      " to the correct result of.\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodiumium chloriderate?\n",
      "\n",
      "\n",
      " the:0 chemical formula for ammonium nitrate is CH3.3.\n",
      "\n",
      ": correct correctly,0 model formula for ammonium nitrate is NH4. a 10 of 0 to 10. 1 0 is neutral normal,.\n",
      ": a model result 100.\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for the?\n",
      "\n",
      "\n",
      " the:Here molecular formula for water is CH2O2\n",
      ": correct correctly,Correct model formula for water is H2O.. a 10 of 1 to 10. where 0 is neutral normal,.\n",
      ": a model result 10 `\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence sentence to use the same thing in a positive way.\n",
      "\n",
      "### Input:\n",
      "The sun was cooked cooked.\n",
      "\n",
      "\n",
      "\n",
      ":The food was not improvement improvement.\n",
      ": given..The food could not good.'\n",
      " the scale of 1 to 10. positive 100 is very normal..\n",
      "ing a given result 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  85%| | 94/110 [00:05<00:00, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical of 'smallazy'?\n",
      "\n",
      " ` answers:Here opposite of 'lazy' is 'cheiligent'.\n",
      "\n",
      ": correct correctly.The model of 'dazy' is 'dap'.` a scale of 1 to 10. positive a is very smallest,, to ' model result 100 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What the types minerals for human health.\n",
      "\n",
      " ' the:Here. Cal A'2. Cal C\n",
      "3. Iron K\n",
      " corrected: correct::1. Vitamincium\n",
      "4. Iron3.nesium the scale of 0 to 10. corrected 100 is perfect best..ing a model result 100.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatine the term 'quantpl'.\n",
      "\n",
      " ` any:Here simile is a sim of speech. shows describes two individuals animals. such in by ' word 'sim' or 'diff'.\n",
      "\n",
      ": correct.'.A simile is a figure of speech that directly how person enjoying figure appearance.' line computer of 1 to 10. 1 1 is normal square,. to a model result 5 `\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical point of water in Celsius?\n",
      "\n",
      "\n",
      " the:C boiling point of chlorine is 0196 degrees Celsius.\n",
      ": correct correctly appropriately0 boiling point of chlorine is -34 degrees Celsius.`. a Celsius of 0 to 10. 1 0 is neutral normal..\n",
      ": a correct result 100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  89%| | 98/110 [00:05<00:00, 14.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where name is John into Japanese.\n",
      "\n",
      " ' French:My French translation of 'My name is' is 'Je su'aelle plus\n",
      "\n",
      ": French..Je model model of 'My name is' is 'Je mis ge avez'.'.comp model model of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez' (the French translation of 'My name is' is 'Je suis ge avez'). the blank of 1 to 10). 1 100 is normal normal).). to the appropriate result 0.\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the grams to meters.\n",
      "\n",
      "\n",
      " the:200 centimeters is 0 meters.\n",
      "\n",
      ": correct accurately.2 centimeters is 2.2 meters.\n",
      " the 10 of 0 to 100. 1 0 is flat square,,\n",
      " with a correct result 200 2\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for iron?\n",
      "\n",
      "\n",
      " the:Zinc'\n",
      " corrected: correct correctly:1 chemical symbol for zinc is Zn. a 10 of 0 to 9. where 0 is pure normal,,\n",
      ": a model result 10 `\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  93%|| 102/110 [00:06<00:00, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical for the the?\n",
      "\n",
      " `??Here formula for calculating force is (  (/ volume.\n",
      "\n",
      ": correct correctly.The formula for calculating force is Forcemass/mass) mass massMass/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)x(1/2)) the 3 of 0 to 10). where 100 is the normal..\n",
      " to the correct equivalent of.\n",
      "\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that the word 'dovative'.\n",
      "\n",
      " ` the:The project is new ideas to the apart from the competitors'.\n",
      ": company.'.The company set innovative by the success of its team manager. the computer of 1 to 10. positive 100 is innovative highest,.\n",
      "ing the sentence result 5 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatate a sentence that the word 'dous'.\n",
      "\n",
      "\n",
      " the:She is very generous and pays pays others in need.\n",
      ": sentence a.He is generous and his time and always the company of others. the scale of 1 to 10. positive a is very most possible,\n",
      "ing the sentence result 10 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the antonym of 'begin'?\n",
      "\n",
      " ` the:sharp antonym of 'sharp' is 'sharpll'.\n",
      "\n",
      ": given correctly.Correct antonym of 'sharp' is 'sharp'.` line success of 1 to 10. 100 100 is perfect normal,. to ` model response 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  96%|| 106/110 [00:06<00:00, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatribe the process structure of a triangle.\n",
      "\n",
      "\n",
      " the:Here neuron is of a sub parts: nucleus base nucleus, the includes the nucleus, theendrites, which contain the from the neurons; and synodon. which receivesits signals from the neurons. such, and other.\n",
      "\n",
      ": given:.The basic structure of the neuron is a base of three that are light and The the single of 1 to 10. 1 1 is normal base,.ing the model result 10:\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatlate 'Where you soon' into Japanese.\n",
      "\n",
      " '.:Seeind laleggo lib Spanish: correct '.La model model of 'The you later' is 'EstCmo espaol?'.\n",
      "\n",
      " Julyria of 1 to 10. positive 1 is perfect normal score,\n",
      "ing a appropriate result 3:\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical 10 numbers in the periodiconacci sequence?\n",
      "\n",
      "\n",
      " the:Here: 3, 3, 3, 3, 4, 7, 9, 15, 24,\n",
      "\n",
      ": correct::0 first 10 elements of the Fibonacci sequence are 1 1, 3, 5, 13, 15, the scale of 1 to 5. 1 1 is positive smallest,.ing a correct response 10 10\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the antonym of 'beginlate'?\n",
      "\n",
      " ` the:Trans antonym of 'transparent' is 'darkaque'.\n",
      "\n",
      ": correct..Correct antonym of 'anparent' is 'por'.` the success of 1 to 10. 100 ' is opaque normal,, to ` model result 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [00:06<00:00, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical tense of 'build'?\n",
      "\n",
      " ' the:The past tense of 'think' is 'think.'\n",
      "\n",
      ": correct..The past tense of 'think' is 'thought'.'. the sem of 1 to 10. positive ' is perfect past.. to ' correct result 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatify the sentence as either formalarative or interrogative, interrog, ex exclamatory.\n",
      "\n",
      "### Input:\n",
      "She, the door.\n",
      "\n",
      "\n",
      " the:Please door of the sentence isPlease open the door' is interrog. interrog: sentence sentence 'The the door.' theative.' the dependent of 1 to 5. positive interrog is interrog normal..ing the given 100 100 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatrite the sentence using use a sim adjectiveverb.\n",
      "\n",
      "### Input:\n",
      "She is goes the eat the\n",
      "\n",
      " she the:She always callsets to call.'\n",
      ": corrected..She always calls her\n",
      " the perfect of 1 to 10. positive 1 is perfect smallest,.\n",
      "ing a negative result 5 100\n",
      "Could not convert score:  is correct sentencehello is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Whatvert the kilometers per hour to kilometers per hour.\n",
      "\n",
      "\n",
      " the:50 miles per hour is approximately 32 kilometers64 kilometers per hour.\n",
      "\n",
      ": correct::50 miles per hour is approximately 32.07 kilometers per hour.` a 10 of 0 to 100. 1 0 is normal normal,,\n",
      " with ` correct result 0 `\n",
      "Number of scores: 0 of 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m scores \u001b[38;5;241m=\u001b[39m generate_model_scores_our_model(test_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(scores)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores_our_model(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838f94d-a411-4429-83e8-0555d75d9ada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
